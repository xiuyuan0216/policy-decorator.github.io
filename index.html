<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Policy Decorator">
  <meta name="keywords" content="Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Policy Decorator</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Policy Decorator: <span style="color: #4da2e4;">Model-Agnostic Online Refinement</span> for Large Policy Model</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="index.html">Xiu Yuan</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://cseweb.ucsd.edu/~t3mu/">Tongzhou Mu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://www.stoneztao.com">Stone Tao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://seerkfang.github.io">Yunhao Fang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="index.html">Mengke Zhang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, San Diego</span>
            <span class="author-block"><sup>2</sup>Hillbot Inc.</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="index.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="index.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="index.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="index.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="index.html"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="columns is-centered">
    <div class="column is-half">
      <h2 class="title is-3" style="text-align: center;">Video</h2>
      <div class="card">
        <div class="card-content">
          <iframe src="https://drive.google.com/file/d/1PwWwFhFTJSUFmEFcrzEEcy5IYHYJ4KLd/preview" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen width="100%" height="400"></iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Recent advancements in robot learning have used imitation learning with large models and extensive demonstrations to develop effective policies. However, these models are often limited by the quantity, quality, and diversity of demonstrations. This paper explores improving offline-trained imitation learning models through online interactions with the environment. We introduce Policy Decorator, which uses a model-agnostic residual policy to refine large imitation learning models during online interactions. By implementing controlled exploration strategies, Policy Decorator enables stable, sample-efficient online learning. Our evaluation spans eight tasks across two benchmarks—ManiSkill and Adroit—and involves two state-of-the-art imitation learning models (Behavior Transformer and Diffusion Policy). The results show Policy Decorator effectively improves the offline-trained policies and preserves the smooth motion of imitation learning models, avoiding the erratic behaviors of pure RL policies.
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">

  <div class="container is-max-desktop">
    <!-- Abstract Section -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Combines Advantages of Base Policy and Online Learning</h2>
        <div class="content has-text-justified">
          An intriguing property of Policy Decorator is its ability to combine the advantages of the base policy and online learning.
        </div>
      </div>
    </div>
  </div>
  

  <div class="container is-max-desktop">
    <div class="columns is-centered">

      <!-- Base Policy -->
      <div class="column is-one-third">
        <div class="card">
          <div class="card-content">
            <h5 class="title is-5">Base Policy (w/o Online Learning)</h5>
            <p>The offline-trained base policies can reproduce the natural and smooth motions recorded in demonstrations but may have suboptimal performance.</p>
            <div class="video-container">
              <video autoplay controls muted loop playsinline height="300px">
                <source src="./static/videos/peg_base.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>

      <!-- Ours (Base Policy + Online Residual) -->
      <div class="column is-one-third">
        <div class="card">
          <div class="card-content">
            <h5 class="title is-5">Ours (Base Policy + Online Residual)</h5>
            <p>Policy Decorator (ours) not only achieves remarkably high success rates but also preserves the favorable attributes of the base policy.</p>
            <div class="video-container">
              <video controls playsinline height="300px">
                <source src="./static/videos/peg_ours.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>

      <!-- Online RL Policy -->
      <div class="column is-one-third">
        <div class="card">
          <div class="card-content">
            <h5 class="title is-5">Online RL Policy (w/o Base Policy)</h5>
            <p>Policies solely learned by RL, though achieving good success rates, often exhibit jerky actions, rendering them unsuitable for real-world applications.</p>
            <div class="video-container">
              <video controls playsinline height="300px">
                <source src="./static/videos/peg_rl.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>

    </div>
  </div>

</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Improve Various SOTA Policy Models</h2>
        <div class="content has-text-justified">
          Our framework, Policy Decorator, improves various state-of-the-art policy models, such as Behavior Transformer and Diffusion Policy, boosting their success rates to nearly 100% on challenging robotic tasks. It also significantly outperforms top-performing baselines from both finetuning and non-finetuning method families.
        </div>
        <div class="content" style="text-align: center;">
          <img src="./static/images/bar_all.jpg"
               class="interpolation-image"
               alt="Interpolate start reference image." width="600" height="400"/>
        </div>        
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          Policy Decorator learns a residual policy via reinforcement learning with sparse reward. On top of it, a set of controlled exploration mechanisms is implemented. 
Controlled exploration (Progressive Exploration Schedule + Bounded Residual Actions) enables the RL agent (both base policy and residual policy) to continuously receive sufficient success signals while exploring the environments. 
        </div>
        <div class="content has-text-justified">
          <img src="./static/images/method_overview.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>Website based on <a href="https://nerfies.github.io">Nerfies</a></p>
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="index.html">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
